> 来源：极客时间《Kafka核心技术与实战》

# 开篇词

**为什么要学习 Kafka?**

日常工作中，如何应对数据量激增、数据复杂度增加以及数据变化速率变化问题？

对于数据量激增来说，Kafka 能够有效隔离上下游业务，将上游突增的流量缓存起来，以平滑的方式传导到下游子系统中。

学习 Kafka 也涉及到其他技术，比如：消息引擎应用、应用程序集成、分布式存储构建、流处理应用的开发与部署。

**如何学习 Kafka?**

第一步：掌握 Kafka 客户端，去官网学习代码示例。

第二步：学习 Kafka 的高级功能，比如流处理应用开发。

**专栏的组成**

![image-20210423230528744](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210423230528.png)

第一部分：消息引擎这类系统原理和用途；

第二部分：Kafka 如何用于生产环境；

第三部分：学习 Kafka 客户端；

第四部分：Kafka 核心设计原理；

第五部分：Kafka 运维与监控；

第六部分：Kafka 流处理组件 Kafka Streams 实战应用；

# 01 | Kafka 介绍

**Kafka 是什么？**

Apache Kafka 是一款开源的消息引擎系统 Messaging System，就像引擎一样，具备某种能量转换传输的能力。

**Kafka 是做什么用的？**

根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。

通俗来讲，就是系统 A 发送消息给消息引擎系统，系统 B 从消息引擎系统中读取 A 发送的消息。

**如何设计消息的传输格式？**

Kafka 使用的是纯二进制的字节序列。消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。

**怎么把消息传输出去？**

常见的有两种方法：

- 点对点模型：系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。
- 发布 / 订阅模型：它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。发送方称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布 / 订阅模型。

**为什么不直接发送而要通过消息引擎发送消息？**

削峰填谷、解耦、异步。这就是 Kafka 这类消息引擎系统的最大意义所在。

以上游的订单系统为例，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。

这就是 Kafka 这类消息引擎系统的最大意义所在。

# 02 | Kafka 术语

- Record：即消息。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
- Topic：即主题。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- Broker：Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。
- Replication：即备份机制。把相同的数据拷贝到多台机器上，这些相同的数据称为副本（Replica）;
- Replica：即副本。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
- Partition。即分区。分区是指一个有序不变的消息序列，每个主题下可以有多个分区。生产者生产的每条消息只会被发送到一个分区中。
- Offset：即消息位移。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- Producer：即生产者。向主题发布新消息的应用程序。
- Consumer：即消费者。从主题订阅新消息的应用程序。
- Consumer Offset：即消费者位移。表征消费者消费进度，每个消费者都有自己的消费者位移。
- Consumer Group：即消费者组。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。利用 Consumer Group 可以实现点对点模型和发布订阅模型。
- Rebalance：即重平衡。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。
- Log：即消息日志。Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。
- Log Segment：即日志段。Kafka 要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。

**Kafka实现高可用的手段**

1. Broker：一台Broker挂掉后，其他机器上的Broker也能对外提供服务；

2. Replication：Kafka 定义了两类副本，领导者副本（Leader Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。

   生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。

   有了副本机制可以保证数据的持久化或消息不丢失。

3. Rebalance 机制；

**Kafka实现伸缩性（Scalability）的手段**

倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？

Kafka 将数据分割成多份保存在不同的 Broker 上，这种机制就是所谓的分区（Partitioning）。

**Kafka实现高吞吐量的手段**

1. Kafka 使用消息日志（Log）来保存数据，Log 是一个只能追加写（Append-only）消息的物理文件，避免了缓慢的随机 I/O 操作；
2. 使用消费者组；

**Kafka磁盘回收的过程**

在 Kafka 底层，是使用 Log 来保存数据的。一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

**分区（Partition）和副本（Replica）的联系**

每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。

生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、…、9。

到此可以总结 Kafka 的三层消息架构：

- 第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
- 第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
- 第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。

**总结**

上面内容可以用一张图来展示。

![image-20201122001949780](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20201122001949.png)

# 03 | Kafka 只是消息引擎系统吗？

Apache Kafka 是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）。

> Kafka 名字的由来
>
> 因为 Kafka 系统的写性能很强，所以找了个作家的名字来命名，Jay Kreps（Kafka 作者之一）大学期间上了很多文学课，非常喜欢 Franz Kafka 这个作家。

**Kafka 的诞生**

Kafka 是 LinkedIn 公司内部孵化的项目。LinkedIn 最开始有强烈的数据强实时处理方面的需求。当时他们碰到的主要问题包括以下两点。

- 数据正确性不足

  因为数据的收集主要采用轮询（Polling）的方式，如何确定轮询的间隔时间就变成了一个高度经验化的事情。

- 系统高度定制化

  维护成本高。

Kafka 消息引擎系统就是为了解决这些问题，旨在提供三个方面的特性：

- 提供一套 API 实现生产者和消费者；
- 降低网络传输和磁盘存储开销；
- 实现高伸缩性架构。

**Kafka 只是消息引擎吗？**

Apache Kafka 是消息引擎系统，也是一个分布式流处理平台（Distributed Streaming Platform）。

Kafka 在承接上下游、串联数据流管道方面发挥了重要的作用：所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。

这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？基于这个考量，Kafka 社区于 0.10.0.0 版本正式推出了流处理组件 Kafka Streams，也正是从这个版本开始，Kafka 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。

**Kafka Streams 流处理平台的优势在哪里？**

- 第一点是更容易实现端到端的正确性（Correctness）

  Kafka 可以实现端到端的精确一次（Exactly-once）处理语义。

- 第二点是 Kafka 对于流式计算的定位

  官网上明确标识 Kafka Streams 是一个用于搭建实时流处理的客户端库而非是一个完整的功能系统。这就是说，你不能期望着 Kafka 提供类似于集群调度、弹性部署等开箱即用的运维特性，你需要自己选择适合的工具或系统来帮助 Kafka 流处理应用实现这些功能。

  > 大型公司的流处理平台一定是大规模部署的，因此具备集群调度功能以及灵活的部署方案是不可或缺的要素。但毕竟这世界上还存在着很多中小企业，它们的流处理数据量并不巨大，逻辑也并不复杂，部署几台或十几台机器足以应付。在这样的需求之下，搭建重量级的完整性平台实在是“杀鸡焉用牛刀”，而这正是 Kafka 流处理组件的用武之地。因此从这个角度来说，未来在流处理框架中，Kafka 应该是有一席之地的。

**Kafka 分布式存储**

Kafka 作者之一 Jay Kreps 曾经专门写过一篇文章阐述为什么能把[Kafka 用作分布式存储](https://www.confluent.io/blog/okay-store-data-apache-kafka/)。不过目前很少有人这么用。

# 04 | 我应该选择哪种Kafka？

整个 Kafka 生态圈如下图所示。

![image-20210424231049846](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210424231050.png)

Kafka Connect 通过一个个具体的连接器（Connector），串联起上下游的外部系统。

由于存在多个组织或公司发布不同的 Kafka，目前市面上主要有以下三种：

**Apache Kafka**

Apache Kafka 是最“正宗”的 Kafka，自 Kafka 开源伊始，它便在 Apache 基金会孵化并最终毕业成为顶级项目，它也被称为社区版 Kafka。

Apache Kafka 的劣势在于它仅仅提供最最基础的组件，特别是对于前面提到的 Kafka Connect 而言，社区版 Kafka 只提供一种连接器，即读写磁盘文件的连接器，而没有与其他外部系统交互的连接器，在实际使用过程中需要自行编写代码实现，这是它的一个劣势。另外 Apache Kafka 没有提供任何监控框架或工具。显然在线上环境不加监控肯定是不可行的，你必然需要借助第三方的监控框架实现对 Kafka 的监控。好消息是目前有一些开源的监控框架可以帮助用于监控 Kafka（比如 Kafka manager）。

如果你仅仅需要一个消息引擎系统亦或是简单的流处理应用场景，同时需要对系统有较大把控度，那么推荐使用 Apache Kafka。

**Confluent Kafka**

2014 年，Kafka 的 3 个创始人 Jay Kreps、Naha Narkhede 和饶军离开 LinkedIn 创办了 Confluent 公司，专注于提供基于 Kafka 的企业级流处理解决方案。Confluent 公司主要从事商业化 Kafka 工具开发，并在此基础上发布了 Confluent Kafka。Confluent Kafka 提供了一些 Apache Kafka 没有的高级特性，比如跨数据中心备份、Schema 注册中心以及集群监控工具等。

Confluent Kafka 目前分为免费版和企业版两种。前者和 Apache Kafka 非常相像，除了常规的组件之外，免费版还包含 Schema 注册中心和 REST proxy 两大功能。前者是帮助你集中管理 Kafka 消息格式以实现数据前向 / 后向兼容；后者用开放 HTTP 接口的方式允许你通过网络访问 Kafka 的各种功能，这两个都是 Apache Kafka 所没有的。

如果你需要用到 Kafka 的一些高级特性，那么推荐你使用 Confluent Kafka。

**Cloudera/Hortonworks Kafka**

Cloudera 提供的 CDH 和 Hortonworks 提供的 HDP 是非常著名的大数据平台，里面集成了目前主流的大数据框架，能够帮助用户实现从分布式存储、集群调度、流处理到机器学习、实时数据库等全方位的数据处理。

CDH/HDP Kafka 天然集成了 Apache Kafka，通过便捷化的界面操作将 Kafka 的安装、运维、管理、监控全部统一在控制台中。如果你是这些平台的用户一定觉得非常方便，因为所有的操作都可以在前端 UI 界面上完成，而不必去执行复杂的 Kafka 命令。另外这些平台提供的监控界面也非常友好，你通常不需要进行任何配置就能有效地监控 Kafka。

如果你需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且 Kafka 只是其中一个组件，那么我推荐你使用这些大数据云公司提供的 Kafka。

# 05 | 聊聊Kafka的版本号

**Kafka 版本命名**

对于 kafka-2.11-2.1.1 的提法， 2.11 是 Scala 编译器版本，真正的 Kafka 版本号实际上是 2.1.1。

前面的 2 表示大版本号，即 Major Version；中间的 1 表示小版本号或次版本号，即 Minor Version；最后的 1 表示修订版本号，也就是 Patch 号。Kafka 社区在发布 1.0.0 版本后特意写过一篇文章，宣布 Kafka 版本命名规则正式从 4 位演进到 3 位，比如 0.11.0.0 版本就是 4 位版本号。

**Kafka 版本演进**

Kafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0。

我们先从 0.7 版本说起，这是最早开源时的“上古”版本了。这个版本只提供了最基础的消息队列功能，甚至连副本机制都没有，不推荐这个版本。

Kafka 到 0.8 之后正式引入了副本机制，至此 Kafka 成为了一个真正意义上完备的分布式高可靠消息队列解决方案。有了副本备份机制，Kafka 就能够比较好地做到消息无丢失。那时候生产和消费消息使用的还是老版本的客户端 API，你需要指定 ZooKeeper 的地址而非 Broker 的地址。

2015 年 11 月，社区正式发布了 0.9.0.0 版本。这是一个重量级的大版本更迭，0.9 大版本增加了基础的安全认证 / 权限功能，同时使用 Java 重写了新版本消费者 API，另外还引入了 Kafka Connect 组件用于实现高性能的数据抽取。新版本 Producer API 在这个版本中算比较稳定了。但是 Consumer API Bug 超多。因此千万别用 0.9 的新版本 Consumer API。

0.10.0.0 是里程碑式的大版本，因为该版本引入了 Kafka Streams。如果你把 Kafka 用作消息引擎，实际上该版本并没有太多的功能提升。不过新版本 Consumer API 算是比较稳定了，强烈建议你至少升级到 0.10.2.2 然后使用新版本 Consumer API。

在 2017 年 6 月，社区发布了 0.11.0.0 版本，引入了两个重量级的功能变更：一个是提供幂等性 Producer API 以及事务（Transaction） API；另一个是对 Kafka 消息格式做了重构。幂等以及事务 API 主要是为 Kafka Streams 应用服务的，因为 Kafka Streams 在做流处理时需要保证结果的正确性。第二个重磅改进是消息格式的变化，消息格式转换可能会导致性能问题。

1.0 和 2.0 这两个大版本主要还是 Kafka Streams 的各种改进，在消息引擎方面并未引入太多的重大功能特性。Kafka Streams 的确在这两个版本有着非常大的变化，也必须承认 Kafka Streams 目前依然还在积极地发展着。如果你是 Kafka Streams 的用户，至少选择 2.0.0 版本吧。

最后还有个建议，不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。

