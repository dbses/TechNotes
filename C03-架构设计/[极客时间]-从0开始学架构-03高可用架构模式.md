# 22 | 想成为架构师，你必须知道CAP理论

**CAP 理论**

第一版解释：

> 对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三个设计约束。

第二版解释：

> 在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。

第二版强调了两点：

- 互相连接和共享数据

  因为分布式系统并不一定会互联和共享数据。最简单的例如 Memcache 的集群，相互之间就没有连接和共享数据，因此 Memcache 集群这类分布式系统就不符合 CAP 理论探讨的对象；而 MySQL 集群就是互联和进行数据复制的，因此是 CAP 理论探讨的对象。

- 读写操作

  CAP 关注的是对数据的读写操作，而不是分布式系统的所有功能。例如，ZooKeeper 的选举机制就不是 CAP 探讨的对象。

相比来说，第二版的定义更加精确。

**一致性（Consistency）**

第一版解释：

> 所有节点在同一时刻都能看到相同的数据。

第二版解释：

> 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。

第一版从节点 node 的角度描述，关键词是看到，强调同一时刻拥有相同数据。

第二版从客户端 client 的角度描述，关键词是写操作。

**可用性（Availability）**

第一版解释：

> 每个请求都能得到成功或者失败的响应。

第二版解释：

> 非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。

第一版强调了每个请求，响应分为成功和失败，

第二版强调了非故障的节点，合理的时间内返回合理的响应。

**分区容忍性（Partition Tolerance）**

第一版解释：

> 出现消息丢失或者分区错误时系统能够继续运行。

第二版解释：

> 当出现网络分区后，系统能够继续起作用。

第一版是运行，描述分区用的是消息丢失或者分区错误；

第二版是起作用，描述分区用的是网络分区；

**CAP 应用**

虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，我们会发现必须选择 P（分区容忍）要素。

如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证 C，系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A 冲突了，因为 A 要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。

1.CP - Consistency/Partition Tolerance

如下图所示，为了保证一致性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。

![image-20210121232648140](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210121232648.png)

2.AP - Availability/Partition Tolerance

如下图所示，为了保证可用性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。注意：这里 N2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。

![image-20210121232719802](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210121232719.png)

**思考题**

基于 Paxos 算法构建的分布式系统，属于 CAP 架构中的哪一种？

# 23 | 想成为架构师，你必须掌握的CAP细节

今天，我来讲讲CAP 的具体细节，简单对比一下 ACID、BASE 几个概念的关键区别点。

**CAP 关键细节点**

- CAP 关注的粒度是数据，而不是整个系统。

在实际设计过程中，每个系统不可能只处理一种数据，而是包含多种类型的数据，有的数据必须选择 CP，有的数据必须选择 AP。而如果我们做设计时，从整个系统的角度去选择 CP 还是 AP，就会发现顾此失彼，无论怎么做都是有问题的。

- CAP 是忽略网络延迟的。

实际情况下，从节点 A 复制数据到节点 B，总是需要花费一定时间的。如果是相同机房，耗费时间可能是几毫秒；如果是跨地域的机房，耗费的时间就可能是几十毫秒。

这就意味着，CAP 理论中的 C 在实践中是不可能完美实现的，在数据复制的过程中，节点 A 和节点 B 的数据并不一致。对于某些严苛的业务场景，例如和金钱相关的用户余额，或者和抢购相关的商品库存，技术上是无法做到分布式场景下完美的一致性的，只能选择 CA。

但系统整体还是可以应用分布式架构的。例如，下面的架构图是常见的将用户分区的分布式架构。

![image-20210123224553959](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210123224554.png)

对于单个用户来说，读写操作都只能在某个节点上进行；对所有用户来说，有一部分用户的读写操作在 Node 1 上，有一部分用户的读写操作在 Node 2 上。

- 放弃并不等于什么都不做，需要为分区恢复后做准备。

分区期间放弃 C 或者 A，并不意味着永远放弃 C 和 A，我们可以在分区期间进行一些操作，从而让分区故障解决后，系统能够重新达到 CA 的状态。

以用户管理系统为例，对于用户账号数据，假设我们选择了 CP，则分区发生后，节点 1 可以继续注册新用户，节点 2 无法注册新用户，此时节点 1 可以将新注册但未同步到节点 2 的用户记录到日志中。当分区恢复后，节点 1 读取日志中的记录，同步给节点 2，当同步完成后，节点 1 和节点 2 就达到了同时满足 CA 的状态。

对于用户信息数据，假设我们选择了 AP，则分区发生后，节点 1 和节点 2 都可以修改用户信息，但两边可能修改不一样。当分区恢复后，系统按照某个规则来合并数据。例如，按照“最后修改优先规则”，按照“字数最多优先规则”，也可以完全将数据冲突报告出来，由人工来选择具体应该采用哪一条。

**ACID**

ACID 是数据库管理系统为了保证事务的正确性而提出来的一个理论，ACID 包含四个约束。

- Atomicity（原子性）

一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。

- Consistency（一致性）

在事务开始之前和事务结束以后，数据库的完整性没有被破坏。

- Isolation（隔离性）

数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。

- Durability（持久性）

事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

ACID 中的 C 和 CAP 中的 C 含义完全不一样。ACID 中的 C 是指数据库的数据完整性，而 CAP 中的 C 是指分布式节点中的数据一致性。

**BASE**

BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency），核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。

- 基本可用（Basically Available）

分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。

- 软状态（Soft State）

允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。

- 最终一致性（Eventual Consistency）

系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。“一定时间”和数据的特性是强关联的，不同的数据能够容忍的不一致时间是不同的。

BASE 理论本质上是对 CAP 中 AP 方案的一个补充。

- CAP 理论是忽略延时的，而实际应用中延时是无法避免的。
- AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。

**思考题**

假如你来设计电商网站的高可用系统，按照 CAP 理论的要求，你会如何设计？

答：一个电商网站核心模块有会员，订单，商品，支付，促销管理等。

对于会员模块，包括登录，个人设置，个人订单，购物车，收藏夹等，这些模块保证AP，数据短时间不一致不影响使用。

订单模块的下单付款扣减库存操作是整个系统的核心，需要保证 CA，在极端情况下牺牲P是可以的。

商品模块的商品上下架和库存管理保证CP。搜索功能因为本身就不是实时性非常高的模块，所以保证AP就可以了。

促销是短时间的数据不一致，结果就是优惠信息看不到，但是已有的优惠要保证可用，而且优惠可以提前预计算，所以可以保证AP。

# 24 | FMEA方法，排除架构可用性隐患的利器

我们在进行架构设计的时候必须全面分析系统的可用性，那么如何才能做到“全面”呢？

**FMEA 介绍**

FMEA 是一套分析和思考的方法，而不是某个领域的技能或者工具。FMEA 并不能指导我们如何做架构设计，而是当我们设计出一个架构后，再使用 FMEA 对这个架构进行分析，看看架构是否还存在某些可用性的隐患。

**FMEA 方法**

FMEA 分析的方法其实很简单，就是一个 FMEA 分析表，常见的 FMEA 分析表格包含下面部分。

1. 功能点

注意这里的“功能点”指的是从用户角度来看的，而不是从系统各个模块功能点划分来看的。

2. 故障模式

故障模式指的是系统会出现什么样的故障，包括故障点和故障形式。例如 MySQL 响应时间达到 3 秒。

3. 故障影响

当发生故障模式中描述的故障时，功能点具体会受到什么影响。

4. 严重程度

严重程度指站在业务的角度故障的影响程度，一般分为“致命 / 高 / 中 / 低 / 无”五个档次。严重程度 = 功能点重要程度 × 故障影响范围 × 功能点受损程度。

5. 故障原因

为何这里还要单独将故障原因列出来呢？主要原因有这几个：

- 不同的故障原因发生概率不相同
- 不同的故障原因检测手段不一样
- 不同的故障原因的处理措施不一样

6. 故障概率

这里的概率就是指某个具体故障原因发生的概率。一般分为“高 / 中 / 低”三档即可，具体评估的时候需要有以下几点需要重点关注。

- 硬件
- 开源系统
- 自研系统

7. 风险程度

风险程度就是综合严重程度和故障概率来一起判断某个故障的最终等级，风险程度 = 严重程度 × 故障概率。

8. 已有措施

针对具体的故障原因，系统现在是否提供了某些措施来应对，包括：检测告警、容错、自恢复等。

9. 规避措施

规避措施指为了降低故障发生概率而做的一些事情，可以是技术手段，也可以是管理手段。

10. 解决措施

解决措施指为了能够解决问题而做的一些事情，一般都是技术手段。

11. 后续规划

综合前面的分析，就可以看出哪些故障我们目前还缺乏对应的措施，哪些已有措施还不够，针对这些不足的地方，再结合风险程度进行排序，给出后续的改进规划。

**FMEA 实战**

下面我以一个简单的样例来模拟一次 FMEA 分析。假设我们设计一个最简单的用户管理系统，包含登录和注册两个功能，其初始架构是：

![image-20210124225257318](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210124225257.png)

我们来看看这个架构通过 FMEA 分析后，能够有什么样的发现，下表是分析的样例：

![image-20210124231440227](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210124231831.png)

经过上表的 FMEA 分析，将“后续规划”列的内容汇总一下，我们最终得到了下面几条需要改进的措施：

- MySQL 增加备机。
- MC 从单机扩展为集群。
- MySQL 双网卡连接。

改进后的架构如下：

![image-20210124231856758](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210124231856.png)

**思考题**

请使用 FMEA 方法分析一下 HDFS 系统的架构，看看 HDFS 是如何应对各种故障的，并且分析一下 HDFS 是否存在高可用问题。

# 25 | 高可用存储架构：双机架构

存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用，对任何一个高可用存储方案，我们需要从以下几个方面去进行思考和分析：

- 数据如何复制？
- 各个节点的职责是什么？
- 如何应对复制延迟？
- 如何应对复制中断？

常见的高可用存储架构有主备、主从、主主、集群、分区。

**主备复制**

主备方案结构图如下：

![image-20210125212015378](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125212015.png)

主备架构中的“备机”主要还是起到一个备份作用，并不承担实际的业务读写操作，如果要把备机改为主机，需要人工操作。

优点：

- 对于客户端来说，不需要感知备机的存在；
- 对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。

缺点：

- 备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费；
- 故障后需要人工干预，无法自动恢复。

**主从复制**

主机负责读写操作，从机只负责读操作，不负责写操作。主从复制架构图如下：

![image-20210125212335788](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125212335.png)

优点：

- 主从复制在主机故障时，读操作相关的业务可以继续运行。
- 主从复制架构的从机提供读操作，发挥了硬件的性能。

缺点：

- 主从复制架构中，客户端需要感知主从关系，复杂度比主备复制要高。
- 会出现主从复制延迟问题。
- 故障时需要人工干预。

**双机切换**

双机切换是为了解决以下这两个问题：

- 主机故障后，无法进行写操作；
- 如果主机无法恢复，需要人工指定新的主机角色。

要实现一个完善的切换方案，必须考虑这几个关键的设计点：

- 主备间状态判断

  主要包括两方面：状态传递的渠道（是相互间互相连接，还是第三方仲裁？），以及状态检测的内容（例如机器是否掉电、进程是否存在、响应是否缓慢等）。

- 切换决策

  主要包括几方面：切换时机、切换策略、自动程度。

- 数据冲突解决

  当原有故障的主机恢复后，新旧主机之间可能存在数据冲突。

**双机切换常见架构**

1. 互连式

互连式就是指主备机直接建立状态传递的渠道，架构图如下：

![image-20210125222218742](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125222218.png)

客户端同时记录主备机的地址，哪个能访问就访问哪个。互连式主备切换主要的缺点在于：

- 如果状态传递的通道本身有故障，那么备机也会认为主机故障了从而将自己升级为主机，而此时主机并没有故障，最终就可能出现两个主机。
- 如果为了解决上个问题使用多个通道，则后续的状态决策会更加复杂，因为对备机来说，可能从不同的通道收到了不同甚至矛盾的状态信息。

2. 中介式

中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息，其架构图如下：

![image-20210125223048543](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125223048.png)

优点：

- 连接管理更简单
- 状态决策更简单

开源方案已经有比较成熟的中介式解决方案，例如 ZooKeeper 和 Keepalived。

3. 模拟式

模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作，根据读写操作的响应情况来判断主机的状态。其基本架构如下：

![image-20210125223558337](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125223558.png)

模拟式读写操作获取的状态信息只有响应信息（例如，HTTP 404，超时、响应时间超过 3 秒等），没有互连式那样多样（除了响应信息，还可以包含 CPU 负载、I/O 负载、吞吐量、响应时间等），基于有限的状态来做状态决策，可能出现偏差。

**主主复制**

主主复制指的是两台机器都是主机，互相将数据复制给对方，客户端可以任意挑选其中一台机器进行读写操作，基本架构图如下：

![image-20210125223947332](https://gitee.com/yanglu_u/ImgRepository/raw/master/images/20210125223947.png)

主主复制架构事实上并不简单，如果采取主主复制架构，必须保证数据能够双向复制，而很多数据是不能双向复制的。例如：

- 用户注册后生成的用户 ID，如果按照数字增长，那就不能双向复制，否则就会出现 X 用户在主机 A 注册，分配的用户 ID 是 100，同时 Y 用户在主机 B 注册，分配的用户 ID 也是 100，这就出现了冲突。
- 库存不能双向复制。例如，一件商品库存 100 件，主机 A 上减了 1 件变成 99，主机 B 上减了 2 件变成 98，然后主机 A 将库存 99 复制到主机 B，主机 B 原有的库存 98 被覆盖，变成了 99，而实际上此时真正的库存是 97。类似的还有余额数据。

因此，主主复制架构对数据的设计有严格的要求，一般适合于那些临时性、可丢失、可覆盖的数据场景。例如，用户登录产生的 session 数据（可以重新登录生成）、用户行为的日志数据（可以丢失）、论坛的草稿数据（可以丢失）等。

**思考题**

如果你来设计一个政府信息公开网站的信息存储系统，你会采取哪种架构？谈谈你的分析和理由。

